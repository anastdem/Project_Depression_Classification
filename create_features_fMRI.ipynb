{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_features_fMRI_Demidova.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "cQby0ByyuHWz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b3b4oLq4uHW3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v2FruSE4uHW7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nilearn import plotting\n",
        "from nilearn.image import concat_imgs\n",
        "from nilearn.input_data import NiftiLabelsMasker\n",
        "from nilearn.image import high_variance_confounds\n",
        "from nilearn.connectome import ConnectivityMeasure"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A6-XTG4vuHW-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nilearn import datasets\n",
        "dataset = datasets.fetch_atlas_aal(version='SPM12', data_dir=None, url=None, resume=True, verbose=1)\n",
        "atlas_filename = dataset.maps\n",
        "labels = dataset.labels\n",
        "l = len(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pBj04GGQuHXB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "masker = NiftiLabelsMasker(labels_img=atlas_filename, background_label = labels, standardize=True, detrend = True, resampling_target = 'labels',\n",
        "                           low_pass=0.08, high_pass=0.009, t_r=3.7, memory='nilearn_cache', memory_level=1, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_QzGbiQ2uHXF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correlation_measure = ConnectivityMeasure(kind='correlation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VcT7rZCRuHXJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "E = ['001', '003', '006', '009', '010', '011', '024', '026', '031', '032', '034', '039', '045', '050', '056', '059', '068', '072','078', '079', '081', '083', '084', '092', '094']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8tzAKaH3uHXM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DE = ['002', '015', '017', '022', '025', '027', '038', '040', '044', '048', '049', '055', '057', '061', '064', '073', '074', '075', '076', '086', '087', '088', '096', '099', '105']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q-udpDdcuHXS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "C = ['008', '013', '018', '033', '036', '037', '043', '046', '047', '051', '054', '062', '077', '080', '082', '085', '089', '090', '091', '093', '098', '100', '106', '107', '108']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1aJZuQVBuHXV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "D = ['004','012','014','016', '019', '020','021','023', '028', '029', '030', '035', '041', '042', '052', '053', '058', '060', '063', '065', '066', '067', '069', '070', '071']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qxj5hnkTuHXY",
        "colab_type": "code",
        "colab": {},
        "outputId": "f58ccd6c-10a0-41c0-f122-93d4571ae4e7"
      },
      "cell_type": "code",
      "source": [
        "P = E+DE+C+D\n",
        "len(P)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "XIgARaTuuHXb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "P = np.sort(P)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rbKVX1wsuHXe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(P)):\n",
        "    img = concat_imgs(\"Brain_functional_data/P\"+P[i]+\"/s\"+P[i]+\"*.nii\", auto_resample=True, verbose=0)\n",
        "    confounds = high_variance_confounds(img, l)\n",
        "    time_series = masker.fit_transform(img, confounds)\n",
        "    correlation_matrix = correlation_measure.fit_transform([time_series])[0]\n",
        "    np.fill_diagonal(correlation_matrix, 0)\n",
        "    Data = pd.DataFrame(correlation_matrix)\n",
        "    Data.to_csv('functional_connenctome/correlation_matrix/P_'+P[i]+'.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QZ1WL2ieuHXi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels.append('0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tdf0f3msuHXl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels.append('1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z8c5bzLluHXo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "column_labels = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p_BQ6fOuuHXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "degree_label = ['degree_'+ labels[i] for i in range(len(labels))]\n",
        "clustering_coefficient_label = ['clustering_coefficient_'+ labels[i] for i in range(len(labels))]\n",
        "average_neighbor_degree_label = ['average_neighbor_degree_'+ labels[i] for i in range(len(labels))]\n",
        "degree_centrality_label = ['degree_centrality_'+ labels[i] for i in range(len(labels))]\n",
        "closeness_centrality_label = ['closeness_centrality_'+ labels[i] for i in range(len(labels))]\n",
        "betweenness_centrality_label = ['betweenness_centrality_'+ labels[i] for i in range(len(labels))]\n",
        "eigenvector_centrality_label = ['eigenvector_centrality_'+ labels[i] for i in range(len(labels))]\n",
        "shortest_path_length_label = ['path_length_'+ labels[i] for i in range(len(labels))]\n",
        "average_clustering_label = ['average_clustering']\n",
        "local_efficiency_label = ['local_efficiency']\n",
        "global_efficiency_label = ['global_efficiency']\n",
        "index_label = ['patient']\n",
        "target_label = ['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rUg73KuxuHXt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "column_labels = degree_label + clustering_coefficient_label + average_neighbor_degree_label + degree_centrality_label + closeness_centrality_label + betweenness_centrality_label + eigenvector_centrality_label + shortest_path_length_label + average_clustering_label + local_efficiency_label + global_efficiency_label + index_label +  target_label "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uqdfgMT-uHXx",
        "colab_type": "code",
        "colab": {},
        "outputId": "b24bf434-c241-4e79-c8db-54225dd1414c"
      },
      "cell_type": "code",
      "source": [
        "len(column_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "941"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "weinXWmxuHX3",
        "colab_type": "code",
        "colab": {},
        "outputId": "415f7347-b443-4183-a214-733350cace61"
      },
      "cell_type": "code",
      "source": [
        "treashold = np.arange(0.5,0.7,0.1)\n",
        "treashold"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.5,  0.6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "7Cxe55xDuHX6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tr in treashold:\n",
        "    Data = pd.DataFrame(columns = column_labels)\n",
        "    for i in range(len(P)):\n",
        "        ft = []\n",
        "        correlation_matrix = pd.read_csv('functional_connenctome/correlation_matrix/P_'+P[i]+'.csv', sep=',').drop('Unnamed: 0', axis = 1)\n",
        "        binary_matrix = abs(correlation_matrix) > tr\n",
        "        G = nx.from_pandas_adjacency(binary_matrix)\n",
        "        degree = [G.degree(i) for i in G.nodes()]\n",
        "        clustering_coefficient = nx.clustering(G)\n",
        "        average_neighbor_degree = nx.average_neighbor_degree(G)\n",
        "        degree_centrality = nx.degree_centrality(G)\n",
        "        closeness_centrality = nx.closeness_centrality(G)\n",
        "        betweenness_centrality = nx.betweenness_centrality(G)\n",
        "        eigenvector_centrality = nx.eigenvector_centrality(G)\n",
        "        shortest_path_length = []\n",
        "         for i in G.nodes():\n",
        "            shortest_path_length.append(sum(nx.single_source_shortest_path_length(G, i).values()))\n",
        "        average_clustering = nx.average_clustering(G)\n",
        "        local_efficiency = nx.local_efficiency(G)\n",
        "        global_efficiency = nx.global_efficiency(G)\n",
        "        ft.extend(degree)\n",
        "        ft.extend(list(clustering_coefficient.values()))\n",
        "        ft.extend(list(average_neighbor_degree.values()))\n",
        "        ft.extend(list(degree_centrality.values()))\n",
        "        ft.extend(list(closeness_centrality.values()))\n",
        "        ft.extend(list(betweenness_centrality.values()))\n",
        "        ft.extend(list(eigenvector_centrality.values()))\n",
        "        ft.extend(shortest_path_length)\n",
        "        ft.append(average_clustering)\n",
        "        ft.append(local_efficiency)\n",
        "        ft.append(global_efficiency)\n",
        "        ft.append('P'+P[i]) \n",
        "        if P[i] in E:\n",
        "            ft.append('E')\n",
        "        if P[i] in D:\n",
        "            ft.append('D')\n",
        "        if P[i] in DE:\n",
        "            ft.append('DE')\n",
        "        if P[i] in C:\n",
        "            ft.append('C')\n",
        "        Data.loc[i] = ft    \n",
        "    Data = Data.rename(columns={587: \"index\", 588: \"target\"})\n",
        "    Data = Data.set_index('index')\n",
        "    Data.to_csv('fMRI_features\\partial_correlation_matrix/features_'+str(tr)+'.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mf9gXDu6uHX8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### t test без корректировки"
      ]
    },
    {
      "metadata": {
        "id": "jD-35Fx4uHYC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "from scipy.stats import t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iWr7PuttuHYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correlation_matrix = pd.read_csv('clean_last/P'+P[i]+'.csv', sep=',').drop('Unnamed: 0', axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C2cRwdS7uHYJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Data = pd.DataFrame(columns = column_labels)\n",
        "for i in range(len(P)):\n",
        "    ft = []\n",
        "    correlation_matrix = pd.read_csv('clean_last/P'+P[i]+'.csv', sep=',').drop('Unnamed: 0', axis = 1)\n",
        "    correlation_matrix = correlation_matrix.as_matrix()\n",
        "    np.fill_diagonal(correlation_matrix, 0)\n",
        "    corr_list = np.reshape(correlation_matrix, (len(correlation_matrix)*len(correlation_matrix)))\n",
        "    transform = list(map(lambda x: x/math.sqrt(1-x**2)*math.sqrt(len(correlation_matrix)-2), corr_list))\n",
        "    t_krit = np.abs(t.ppf(0.01/2, len(correlation_matrix)-2, loc=0, scale=1))\n",
        "    bin_list = np.abs(transform) > t_krit\n",
        "    binary_matrix = np.reshape(bin_list, (len(correlation_matrix), len(correlation_matrix)))\n",
        "    G = nx.from_numpy_matrix(binary_matrix)\n",
        "    degree = [G.degree(i) for i in G.nodes()]\n",
        "    clustering_coefficient = nx.clustering(G)\n",
        "    average_neighbor_degree = nx.average_neighbor_degree(G)\n",
        "    degree_centrality = nx.degree_centrality(G)\n",
        "    closeness_centrality = nx.closeness_centrality(G)\n",
        "    betweenness_centrality = nx.betweenness_centrality(G)\n",
        "    eigenvector_centrality = nx.eigenvector_centrality(G)\n",
        "    shortest_path_length = []\n",
        "    for k in G.nodes():\n",
        "        shortest_path_length.append(sum(nx.single_source_shortest_path_length(G, k).values()))\n",
        "    average_clustering = nx.average_clustering(G)\n",
        "    local_efficiency = nx.local_efficiency(G)\n",
        "    global_efficiency = nx.global_efficiency(G)\n",
        "    ft.extend(degree)\n",
        "    ft.extend(list(clustering_coefficient.values()))\n",
        "    ft.extend(list(average_neighbor_degree.values()))\n",
        "    ft.extend(list(degree_centrality.values()))\n",
        "    ft.extend(list(closeness_centrality.values()))\n",
        "    ft.extend(list(betweenness_centrality.values()))\n",
        "    ft.extend(list(eigenvector_centrality.values()))\n",
        "    ft.extend(shortest_path_length)\n",
        "    ft.append(average_clustering)\n",
        "    ft.append(local_efficiency)\n",
        "    ft.append(global_efficiency)\n",
        "    ft.append('P'+P[i]) \n",
        "    if P[i] in E:\n",
        "        ft.append('E')\n",
        "    if P[i] in D:\n",
        "        ft.append('D')\n",
        "    if P[i] in DE:\n",
        "        ft.append('DE')\n",
        "    if P[i] in C:\n",
        "        ft.append('C')\n",
        "    Data.loc[i] = ft    \n",
        "Data.to_csv('fmri_feature_correlation_significance/0.01/manual/features_ttest.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OqM8Zo7quHYL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(P)):\n",
        "    correlation_matrix = pd.read_csv('functional_connenctome/correlation_matrix/P_'+P[i]+'.csv', sep=',').drop('Unnamed: 0', axis = 1)\n",
        "    correlation_matrix = correlation_matrix.as_matrix()\n",
        "    np.fill_diagonal(correlation_matrix, 0)\n",
        "    corr_list = np.reshape(correlation_matrix, (len(correlation_matrix)*len(correlation_matrix)))\n",
        "    transform = list(map(lambda x: x/math.sqrt(1-x**2)*math.sqrt(len(correlation_matrix)-2), corr_list))\n",
        "    t_krit = np.abs(t.ppf(0.1/2, len(correlation_matrix)-2, loc=0, scale=1))\n",
        "    corr_list_ttest = [0]*(len(correlation_matrix)*len(correlation_matrix))\n",
        "    for j in range(len(transform)):\n",
        "        if np.abs(transform[j]) > t_krit:\n",
        "            corr_list_ttest[j] = corr_list[j]\n",
        "    correlation_matrix_ttest = np.reshape(corr_list_ttest, (len(correlation_matrix), len(correlation_matrix))) \n",
        "    correlation_matrix_ttest = pd.DataFrame(correlation_matrix_ttest)\n",
        "    correlation_matrix_ttest.to_csv('functional_connenctome/correlation_matrix_ttest/0.1/P_'+P[i]+'.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-RceZ2ZNuHYN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Bonferoni"
      ]
    },
    {
      "metadata": {
        "id": "pwyqA9uUuHYO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Data = pd.DataFrame(columns = column_labels)\n",
        "for i in range(len(P)):\n",
        "    ft = []\n",
        "    correlation_matrix = pd.read_csv('clean_last/P'+P[i]+'.csv', sep=',').drop('Unnamed: 0', axis = 1)\n",
        "    correlation_matrix = correlation_matrix.as_matrix()\n",
        "    np.fill_diagonal(correlation_matrix, 0)\n",
        "    corr_list = np.reshape(correlation_matrix, (len(correlation_matrix)*len(correlation_matrix)))\n",
        "    transform = list(map(lambda x: x/math.sqrt(1-x**2)*math.sqrt(len(correlation_matrix)-2), corr_list))\n",
        "    t_krit = np.abs(t.ppf((0.1/2)/(len(correlation_matrix)*len(correlation_matrix)), len(correlation_matrix)-2))\n",
        "    bin_list = np.abs(transform) > t_krit\n",
        "    binary_matrix = np.reshape(bin_list, (len(correlation_matrix), len(correlation_matrix)))\n",
        "    G = nx.from_numpy_matrix(binary_matrix)\n",
        "    degree = [G.degree(i) for i in G.nodes()]\n",
        "    clustering_coefficient = nx.clustering(G)\n",
        "    average_neighbor_degree = nx.average_neighbor_degree(G)\n",
        "    degree_centrality = nx.degree_centrality(G)\n",
        "    closeness_centrality = nx.closeness_centrality(G)\n",
        "    betweenness_centrality = nx.betweenness_centrality(G)\n",
        "    #eigenvector_centrality = nx.eigenvector_centrality(G)\n",
        "    shortest_path_length = []\n",
        "    for k in G.nodes():\n",
        "        shortest_path_length.append(sum(nx.single_source_shortest_path_length(G, k).values()))\n",
        "    average_clustering = nx.average_clustering(G)\n",
        "    local_efficiency = nx.local_efficiency(G)\n",
        "    global_efficiency = nx.global_efficiency(G)\n",
        "    ft.extend(degree)\n",
        "    ft.extend(list(clustering_coefficient.values()))\n",
        "    ft.extend(list(average_neighbor_degree.values()))\n",
        "    ft.extend(list(degree_centrality.values()))\n",
        "    ft.extend(list(closeness_centrality.values()))\n",
        "    ft.extend(list(betweenness_centrality.values()))\n",
        "    #ft.extend(list(eigenvector_centrality.values()))\n",
        "    ft.extend(shortest_path_length)\n",
        "    ft.append(average_clustering)\n",
        "    ft.append(local_efficiency)\n",
        "    ft.append(global_efficiency)\n",
        "    ft.append('P'+P[i]) \n",
        "    if P[i] in E:\n",
        "        ft.append('E')\n",
        "    if P[i] in D:\n",
        "        ft.append('D')\n",
        "    if P[i] in DE:\n",
        "        ft.append('DE')\n",
        "    if P[i] in C:\n",
        "        ft.append('C')\n",
        "    Data.loc[i] = ft    \n",
        "Data.to_csv('fmri_feature_correlation_significance/0.1/manual/features_bonferoni.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w5ZlPqtbuHYQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Benjamini–Hochberg–Yekutieli procedure"
      ]
    },
    {
      "metadata": {
        "id": "39AgurKFuHYR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def c(x):\n",
        "    sum = 0\n",
        "    for i in range(1,x+1):\n",
        "        sum = sum + 1./i\n",
        "    return sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nMjbIonduHYY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Data = pd.DataFrame(columns = column_labels)\n",
        "for i in range(len(P)):\n",
        "    ft = []\n",
        "    correlation_matrix = pd.read_csv('clean_last/P'+P[i]+'.csv', sep=',').drop('Unnamed: 0', axis = 1)\n",
        "    correlation_matrix = correlation_matrix.as_matrix()\n",
        "    np.fill_diagonal(correlation_matrix, 0)\n",
        "    corr_list = np.reshape(correlation_matrix, (len(correlation_matrix)*len(correlation_matrix)))\n",
        "    transform = list(map(lambda x: x/math.sqrt(1-x**2)*math.sqrt(len(correlation_matrix)-2), corr_list))\n",
        "    pvalue = np.abs(t.sf(transform, len(correlation_matrix)-2))\n",
        "    ind = np.argsort(pvalue)\n",
        "    pvalue_sort = np.sort(pvalue)\n",
        "    bin_list = [False]*(len(correlation_matrix)*len(correlation_matrix))\n",
        "    cm = c(len(correlation_matrix)*len(correlation_matrix))\n",
        "    for j in range(len(bin_list)):\n",
        "        if 2*pvalue_sort[j]*(len(correlation_matrix)*len(correlation_matrix))*cm/(j+1) < 0.05:\n",
        "            bin_list[j] = True\n",
        "        else: break\n",
        "    bin_list_order = [False]*(len(correlation_matrix)*len(correlation_matrix)) \n",
        "    for j in range(len(bin_list)):\n",
        "        bin_list_order[ind[j]] = bin_list[j]\n",
        "    binary_matrix = np.reshape(bin_list_order, (len(correlation_matrix), len(correlation_matrix))) \n",
        "    G = nx.from_numpy_matrix(binary_matrix)\n",
        "    degree = [G.degree(x) for x in G.nodes()]\n",
        "    clustering_coefficient = nx.clustering(G)\n",
        "    average_neighbor_degree = nx.average_neighbor_degree(G)\n",
        "    degree_centrality = nx.degree_centrality(G)\n",
        "    closeness_centrality = nx.closeness_centrality(G)\n",
        "    betweenness_centrality = nx.betweenness_centrality(G)\n",
        "    eigenvector_centrality = nx.eigenvector_centrality(G)\n",
        "    shortest_path_length = []\n",
        "    for k in G.nodes():\n",
        "        shortest_path_length.append(sum(nx.single_source_shortest_path_length(G, k).values()))\n",
        "    average_clustering = nx.average_clustering(G)\n",
        "    local_efficiency = nx.local_efficiency(G)\n",
        "    global_efficiency = nx.global_efficiency(G)\n",
        "    ft.extend(degree)\n",
        "    ft.extend(list(clustering_coefficient.values()))\n",
        "    ft.extend(list(average_neighbor_degree.values()))\n",
        "    ft.extend(list(degree_centrality.values()))\n",
        "    ft.extend(list(closeness_centrality.values()))\n",
        "    ft.extend(list(betweenness_centrality.values()))\n",
        "    ft.extend(list(eigenvector_centrality.values()))\n",
        "    ft.extend(shortest_path_length)\n",
        "    ft.append(average_clustering)\n",
        "    ft.append(local_efficiency)\n",
        "    ft.append(global_efficiency)\n",
        "    ft.append('P'+P[i]) \n",
        "    if P[i] in E:\n",
        "        ft.append('E')\n",
        "    if P[i] in D:\n",
        "        ft.append('D')\n",
        "    if P[i] in DE:\n",
        "        ft.append('DE')\n",
        "    if P[i] in C:\n",
        "        ft.append('C')\n",
        "    Data.loc[i] = ft    \n",
        "Data.to_csv('fmri_feature_correlation_significance/0.05/manual/features_BHY.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dFu5CsX0uHYm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "buGO0PGduHYo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}